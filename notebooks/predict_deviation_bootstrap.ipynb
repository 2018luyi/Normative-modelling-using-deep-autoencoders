{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Normative_prediciton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Warvito/Normative-modelling-using-deep-autoencoders/blob/master/notebooks/predict_deviation_bootstrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YVZp-35UpNAK"
      },
      "source": [
        "# Deviation scores using all trained models\n",
        "\n",
        "Here in this notebook, we implemented an easy way to you try our normative models based on autoencoders trained on the UK Biobank data. **Disclaimer**: this script can not be used for clinical purposes.\n",
        "\n",
        "Let's start!\n",
        "\n",
        "---\n",
        "## Enabling the GPU\n",
        "\n",
        "First, you'll need to enable [GPUs](https://cloud.google.com/gpu) for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rUzvR_q4tFKV"
      },
      "source": [
        "## Load trained models\n",
        "Next, we will load the trained normative models into this colab environment. In our study, we trained 1,000 different models on the UK BIobank using the resampling method called bootstrap method.\n",
        "\n",
        "All the saved files are available at https://www.dropbox.com/s/bs89t2davs1p2dm/models_for_normative_paper_2019.zip?dl=0 .\n",
        "\n",
        "This zipped file contains the models files created using the  bootstrap_train_aae_supervised.py script. The models files are organized in subdirectories where each one correspond to a bootstrap iteration. In each iteration, we stored the data scaler, the age and gender encoders, and the encoder and decoder of the normative model.\n",
        "\n",
        "Besides the models, the zipped file contains two templates files (used later in this notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xUw80taSTjWW",
        "outputId": "fe379088-05d7-4278-8419-23d8dee45c07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "!wget -O models.zip --no-check-certificate https://www.dropbox.com/s/bs89t2davs1p2dm/models_for_normative_paper_2019.zip?dl=0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-04 16:42:10--  https://www.dropbox.com/s/bs89t2davs1p2dm/models_for_normative_paper_2019.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/bs89t2davs1p2dm/models_for_normative_paper_2019.zip [following]\n",
            "--2019-12-04 16:42:10--  https://www.dropbox.com/s/raw/bs89t2davs1p2dm/models_for_normative_paper_2019.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc4a51b3038a85342edc1a67243d.dl.dropboxusercontent.com/cd/0/inline/Atn60gy3Ie-65D_7iYQUfRoiqy_knjTZUqAGyTO-L82Kq9QF9fh2wUGA9puU_TjpTiuBSfhszHNhDxec9ikTnObWziRRxYiFGISVA9bCm-CjMgCMduV_0kliQGqHrLIb52M/file# [following]\n",
            "--2019-12-04 16:42:11--  https://uc4a51b3038a85342edc1a67243d.dl.dropboxusercontent.com/cd/0/inline/Atn60gy3Ie-65D_7iYQUfRoiqy_knjTZUqAGyTO-L82Kq9QF9fh2wUGA9puU_TjpTiuBSfhszHNhDxec9ikTnObWziRRxYiFGISVA9bCm-CjMgCMduV_0kliQGqHrLIb52M/file\n",
            "Resolving uc4a51b3038a85342edc1a67243d.dl.dropboxusercontent.com (uc4a51b3038a85342edc1a67243d.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to uc4a51b3038a85342edc1a67243d.dl.dropboxusercontent.com (uc4a51b3038a85342edc1a67243d.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/Atl5P_mRGnlcdkGzPA_canB8Q1lM2Rb2wtBG-xpB-sFOSeIRoCvp7mFUhrzyXihjcH0O2zriiZ1r1JZK0jaBftbBtbsuifgV7sMk1vUK_dCNLUrEVeOfMLNPh9qhG-HRpF5D7r4HBUYvrSBzIIT0NXxWZQNAS7UemN5vHiuqHJNG9Ias4xjWKWJLCvtnHpD5ed2Xp0lVJ67KUS84HFbWQbXFwGz1hXp4PYRXJSyBinCzborVYyyWxOI_rcUJOPWdaKJ-PDSDvOXJkj8FZtUPHuGaNy4k751DOKxe7NxPDcdOggs7m7l-yf6End1RpputuA-DyFrGvP1Zxm1eC0CzopBVHDfDxBxuz31SUGmfVQAcAA/file [following]\n",
            "--2019-12-04 16:42:11--  https://uc4a51b3038a85342edc1a67243d.dl.dropboxusercontent.com/cd/0/inline2/Atl5P_mRGnlcdkGzPA_canB8Q1lM2Rb2wtBG-xpB-sFOSeIRoCvp7mFUhrzyXihjcH0O2zriiZ1r1JZK0jaBftbBtbsuifgV7sMk1vUK_dCNLUrEVeOfMLNPh9qhG-HRpF5D7r4HBUYvrSBzIIT0NXxWZQNAS7UemN5vHiuqHJNG9Ias4xjWKWJLCvtnHpD5ed2Xp0lVJ67KUS84HFbWQbXFwGz1hXp4PYRXJSyBinCzborVYyyWxOI_rcUJOPWdaKJ-PDSDvOXJkj8FZtUPHuGaNy4k751DOKxe7NxPDcdOggs7m7l-yf6End1RpputuA-DyFrGvP1Zxm1eC0CzopBVHDfDxBxuz31SUGmfVQAcAA/file\n",
            "Reusing existing connection to uc4a51b3038a85342edc1a67243d.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 185725753 (177M) [application/zip]\n",
            "Saving to: ‘models.zip’\n",
            "\n",
            "models.zip           22%[===>                ]  39.92M   447KB/s    eta 5m 6s  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eHi0frcUvjWV"
      },
      "source": [
        "## Unzipping models files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TOBm7DBZWu-i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d88abec5-0d5b-4dbf-d71c-2b37dd532ee5"
      },
      "source": [
        "!unzip models.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  models.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of models.zip or\n",
            "        models.zip.zip, and cannot find models.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b-FkF6BDvsgV"
      },
      "source": [
        "As showed below, in the Google colab environment, there is an arrow mark which looks like “>” at the left-hand side of the cells.\n",
        "\n",
        "<img src=\"https://github.com/Warvito/Normative-modelling-using-deep-autoencoders/blob/master/notebooks/figures/files.png?raw=1\">\n",
        "\n",
        "When you click that you will find a tab with three options, just have to select “Files” to explore the loaded models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hjjJikyJwniF"
      },
      "source": [
        "## Importing Python libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92qHTRkXYOZS",
        "outputId": "1864849b-100c-4ad5-84cc-f8c01f699cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from google.colab import files\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lr9ZTT8jrtJk",
        "outputId": "d235b197-dc4d-4c29-be3c-a7dc937a350f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CLo1uoS8wytB"
      },
      "source": [
        "## Downloading freesurferData.csv and participants.tsv templates\n",
        "In order to make predictions of your data, it is necessary to make it in the format to correctly read by this script. To facilitate this process, we supply the template files to be filled with your data.\n",
        "\n",
        "As shown below, these template files contain the names of the necessary columns to run the script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QO5bnmgYxi7y",
        "outputId": "efabd119-090b-4019-d30b-fda9abb0b53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "pd.read_csv('freesurferData.csv')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Participant_ID</th>\n",
              "      <th>EstimatedTotalIntraCranialVol</th>\n",
              "      <th>Left-Lateral-Ventricle</th>\n",
              "      <th>Left-Inf-Lat-Vent</th>\n",
              "      <th>Left-Cerebellum-White-Matter</th>\n",
              "      <th>Left-Cerebellum-Cortex</th>\n",
              "      <th>Left-Thalamus-Proper</th>\n",
              "      <th>Left-Caudate</th>\n",
              "      <th>Left-Putamen</th>\n",
              "      <th>Left-Pallidum</th>\n",
              "      <th>3rd-Ventricle</th>\n",
              "      <th>4th-Ventricle</th>\n",
              "      <th>Brain-Stem</th>\n",
              "      <th>Left-Hippocampus</th>\n",
              "      <th>Left-Amygdala</th>\n",
              "      <th>CSF</th>\n",
              "      <th>Left-Accumbens-area</th>\n",
              "      <th>Left-VentralDC</th>\n",
              "      <th>Right-Lateral-Ventricle</th>\n",
              "      <th>Right-Inf-Lat-Vent</th>\n",
              "      <th>Right-Cerebellum-White-Matter</th>\n",
              "      <th>Right-Cerebellum-Cortex</th>\n",
              "      <th>Right-Thalamus-Proper</th>\n",
              "      <th>Right-Caudate</th>\n",
              "      <th>Right-Putamen</th>\n",
              "      <th>Right-Pallidum</th>\n",
              "      <th>Right-Hippocampus</th>\n",
              "      <th>Right-Amygdala</th>\n",
              "      <th>Right-Accumbens-area</th>\n",
              "      <th>Right-VentralDC</th>\n",
              "      <th>CC_Posterior</th>\n",
              "      <th>CC_Mid_Posterior</th>\n",
              "      <th>CC_Central</th>\n",
              "      <th>CC_Mid_Anterior</th>\n",
              "      <th>CC_Anterior</th>\n",
              "      <th>lh_bankssts_volume</th>\n",
              "      <th>lh_caudalanteriorcingulate_volume</th>\n",
              "      <th>lh_caudalmiddlefrontal_volume</th>\n",
              "      <th>lh_cuneus_volume</th>\n",
              "      <th>lh_entorhinal_volume</th>\n",
              "      <th>...</th>\n",
              "      <th>lh_superiortemporal_volume</th>\n",
              "      <th>lh_supramarginal_volume</th>\n",
              "      <th>lh_frontalpole_volume</th>\n",
              "      <th>lh_temporalpole_volume</th>\n",
              "      <th>lh_transversetemporal_volume</th>\n",
              "      <th>lh_insula_volume</th>\n",
              "      <th>rh_bankssts_volume</th>\n",
              "      <th>rh_caudalanteriorcingulate_volume</th>\n",
              "      <th>rh_caudalmiddlefrontal_volume</th>\n",
              "      <th>rh_cuneus_volume</th>\n",
              "      <th>rh_entorhinal_volume</th>\n",
              "      <th>rh_fusiform_volume</th>\n",
              "      <th>rh_inferiorparietal_volume</th>\n",
              "      <th>rh_inferiortemporal_volume</th>\n",
              "      <th>rh_isthmuscingulate_volume</th>\n",
              "      <th>rh_lateraloccipital_volume</th>\n",
              "      <th>rh_lateralorbitofrontal_volume</th>\n",
              "      <th>rh_lingual_volume</th>\n",
              "      <th>rh_medialorbitofrontal_volume</th>\n",
              "      <th>rh_middletemporal_volume</th>\n",
              "      <th>rh_parahippocampal_volume</th>\n",
              "      <th>rh_paracentral_volume</th>\n",
              "      <th>rh_parsopercularis_volume</th>\n",
              "      <th>rh_parsorbitalis_volume</th>\n",
              "      <th>rh_parstriangularis_volume</th>\n",
              "      <th>rh_pericalcarine_volume</th>\n",
              "      <th>rh_postcentral_volume</th>\n",
              "      <th>rh_posteriorcingulate_volume</th>\n",
              "      <th>rh_precentral_volume</th>\n",
              "      <th>rh_precuneus_volume</th>\n",
              "      <th>rh_rostralanteriorcingulate_volume</th>\n",
              "      <th>rh_rostralmiddlefrontal_volume</th>\n",
              "      <th>rh_superiorfrontal_volume</th>\n",
              "      <th>rh_superiorparietal_volume</th>\n",
              "      <th>rh_superiortemporal_volume</th>\n",
              "      <th>rh_supramarginal_volume</th>\n",
              "      <th>rh_frontalpole_volume</th>\n",
              "      <th>rh_temporalpole_volume</th>\n",
              "      <th>rh_transversetemporal_volume</th>\n",
              "      <th>rh_insula_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sub-X</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 103 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Participant_ID  ...  rh_insula_volume\n",
              "0          sub-X  ...                 1\n",
              "\n",
              "[1 rows x 103 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pKl3fXWgxs8q",
        "outputId": "19df8894-57bf-49c2-c1d6-2c491f0fa264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "pd.read_csv('participants.tsv', sep='\\t')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Participant_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sub-X</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Participant_ID  Gender  Age\n",
              "0          sub-X       0   60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8vlfd-XWxxZv"
      },
      "source": [
        "* Note: The column with gender is codified as 0 = \"Female\" and 1 = \"Male\".\n",
        "\n",
        "The next cells will start the download of the templates.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jUub_LWSZ-FW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a4b315f4-f860-42fc-a08f-9a2edeedfe87"
      },
      "source": [
        "files.download('templates/freesurferData.csv')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4840d7e66767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'templates/freesurferData.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0mstarted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_threading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: templates/freesurferData.csv"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CC_YY2N-dJ9G",
        "colab": {}
      },
      "source": [
        "files.download('templates/participants.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3oPjKCaPx5qu"
      },
      "source": [
        "After filled the templates, upload the files to the Google colab environment.\n",
        "\n",
        "**Note: You can create the freesurferData.csv file using our colab script on this** [link](https://colab.research.google.com/github/Warvito/Normative-modelling-using-deep-autoencoders/blob/master/notebooks/freesurfer_organizer.ipynb).\n",
        "\n",
        "Note2: Your data will only be loaded in this runtime of the Google colab. This code is being executed at the Google Cloud Platform by default, and you are not making your data available for our team. If you are concern about uploading your data to the Google Cloud Platform, please, consider executing this notebook in a local runtime in your computer (https://research.google.com/colaboratory/local-runtimes.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UOlTkfiwzg47"
      },
      "source": [
        "First, start uploading the freesurferData.csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gujhqPurZpxn",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_-l3-DNczoC5"
      },
      "source": [
        "Then, upload the participants.tsv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whliHlezdPVr",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn2 in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn2, length=len(uploaded[fn2])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X3dIqTAdbwTt",
        "colab": {}
      },
      "source": [
        "freesurfer_data_df = pd.read_csv(fn)\n",
        "participants_df = pd.read_csv(fn2, sep='\\t')\n",
        "\n",
        "dataset_df = pd.merge(freesurfer_data_df, participants_df, on='Participant_ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SgWfFTNJiTx0",
        "colab": {}
      },
      "source": [
        "dataset_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qPT20CsLzx83"
      },
      "source": [
        "## Predicting the deviations\n",
        "After loading the data, we predict the deviations of the new data based on our trained normative models.\n",
        "\n",
        "We begin the processing by setting the random seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H4FmSLM5aq5q",
        "colab": {}
      },
      "source": [
        "# Set random seed\n",
        "random_seed = 42\n",
        "tf.random.set_seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HJScNag1ik3e"
      },
      "source": [
        "Next, we define the name of the brain regions in the variable COLUMNS_NAME."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N9ymq42YirBj",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "COLUMNS_NAME = ['Left-Lateral-Ventricle',\n",
        "                'Left-Inf-Lat-Vent',\n",
        "                'Left-Cerebellum-White-Matter',\n",
        "                'Left-Cerebellum-Cortex',\n",
        "                'Left-Thalamus-Proper',\n",
        "                'Left-Caudate',\n",
        "                'Left-Putamen',\n",
        "                'Left-Pallidum',\n",
        "                '3rd-Ventricle',\n",
        "                '4th-Ventricle',\n",
        "                'Brain-Stem',\n",
        "                'Left-Hippocampus',\n",
        "                'Left-Amygdala',\n",
        "                'CSF',\n",
        "                'Left-Accumbens-area',\n",
        "                'Left-VentralDC',\n",
        "                'Right-Lateral-Ventricle',\n",
        "                'Right-Inf-Lat-Vent',\n",
        "                'Right-Cerebellum-White-Matter',\n",
        "                'Right-Cerebellum-Cortex',\n",
        "                'Right-Thalamus-Proper',\n",
        "                'Right-Caudate',\n",
        "                'Right-Putamen',\n",
        "                'Right-Pallidum',\n",
        "                'Right-Hippocampus',\n",
        "                'Right-Amygdala',\n",
        "                'Right-Accumbens-area',\n",
        "                'Right-VentralDC',\n",
        "                'CC_Posterior',\n",
        "                'CC_Mid_Posterior',\n",
        "                'CC_Central',\n",
        "                'CC_Mid_Anterior',\n",
        "                'CC_Anterior',\n",
        "                'lh_bankssts_volume',\n",
        "                'lh_caudalanteriorcingulate_volume',\n",
        "                'lh_caudalmiddlefrontal_volume',\n",
        "                'lh_cuneus_volume',\n",
        "                'lh_entorhinal_volume',\n",
        "                'lh_fusiform_volume',\n",
        "                'lh_inferiorparietal_volume',\n",
        "                'lh_inferiortemporal_volume',\n",
        "                'lh_isthmuscingulate_volume',\n",
        "                'lh_lateraloccipital_volume',\n",
        "                'lh_lateralorbitofrontal_volume',\n",
        "                'lh_lingual_volume',\n",
        "                'lh_medialorbitofrontal_volume',\n",
        "                'lh_middletemporal_volume',\n",
        "                'lh_parahippocampal_volume',\n",
        "                'lh_paracentral_volume',\n",
        "                'lh_parsopercularis_volume',\n",
        "                'lh_parsorbitalis_volume',\n",
        "                'lh_parstriangularis_volume',\n",
        "                'lh_pericalcarine_volume',\n",
        "                'lh_postcentral_volume',\n",
        "                'lh_posteriorcingulate_volume',\n",
        "                'lh_precentral_volume',\n",
        "                'lh_precuneus_volume',\n",
        "                'lh_rostralanteriorcingulate_volume',\n",
        "                'lh_rostralmiddlefrontal_volume',\n",
        "                'lh_superiorfrontal_volume',\n",
        "                'lh_superiorparietal_volume',\n",
        "                'lh_superiortemporal_volume',\n",
        "                'lh_supramarginal_volume',\n",
        "                'lh_frontalpole_volume',\n",
        "                'lh_temporalpole_volume',\n",
        "                'lh_transversetemporal_volume',\n",
        "                'lh_insula_volume',\n",
        "                'rh_bankssts_volume',\n",
        "                'rh_caudalanteriorcingulate_volume',\n",
        "                'rh_caudalmiddlefrontal_volume',\n",
        "                'rh_cuneus_volume',\n",
        "                'rh_entorhinal_volume',\n",
        "                'rh_fusiform_volume',\n",
        "                'rh_inferiorparietal_volume',\n",
        "                'rh_inferiortemporal_volume',\n",
        "                'rh_isthmuscingulate_volume',\n",
        "                'rh_lateraloccipital_volume',\n",
        "                'rh_lateralorbitofrontal_volume',\n",
        "                'rh_lingual_volume',\n",
        "                'rh_medialorbitofrontal_volume',\n",
        "                'rh_middletemporal_volume',\n",
        "                'rh_parahippocampal_volume',\n",
        "                'rh_paracentral_volume',\n",
        "                'rh_parsopercularis_volume',\n",
        "                'rh_parsorbitalis_volume',\n",
        "                'rh_parstriangularis_volume',\n",
        "                'rh_pericalcarine_volume',\n",
        "                'rh_postcentral_volume',\n",
        "                'rh_posteriorcingulate_volume',\n",
        "                'rh_precentral_volume',\n",
        "                'rh_precuneus_volume',\n",
        "                'rh_rostralanteriorcingulate_volume',\n",
        "                'rh_rostralmiddlefrontal_volume',\n",
        "                'rh_superiorfrontal_volume',\n",
        "                'rh_superiorparietal_volume',\n",
        "                'rh_superiortemporal_volume',\n",
        "                'rh_supramarginal_volume',\n",
        "                'rh_frontalpole_volume',\n",
        "                'rh_temporalpole_volume',\n",
        "                'rh_transversetemporal_volume',\n",
        "                'rh_insula_volume']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bw9sBiGwiBN9"
      },
      "source": [
        "Then, we calculate the relative brain region volumes (original volume divided by the total intracranial volume). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ae1dT-5O1Fln",
        "colab": {}
      },
      "source": [
        "# Get the relative brain region volumes\n",
        "x_dataset = dataset_df[COLUMNS_NAME].values\n",
        "\n",
        "tiv = dataset_df['EstimatedTotalIntraCranialVol'].values\n",
        "tiv = tiv[:, np.newaxis]\n",
        "\n",
        "x_dataset = (np.true_divide(x_dataset, tiv)).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5F8WZKzc1O-v"
      },
      "source": [
        "Next, we iterate over all models performing the calculation of the deviations.\n",
        "\n",
        "* Note: if the age of the subject in lower than 47 or higher than 73, the age value will be clipped the be inside the range (47,73), for example, if someone has age = 40, it will be rounded to 47.\n",
        "\n",
        "\n",
        "dataset.loc[(dataset['Age'] >= 47) & (dataset['Age'] <= 73)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eXcs1zxWaw-w",
        "colab": {}
      },
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "model_dir = Path('models')\n",
        "N_BOOTSTRAP = 1000\n",
        "\n",
        "# Create dataframe to store outputs\n",
        "reconstruction_error_df = pd.DataFrame(columns=['Participant_ID'])\n",
        "reconstruction_error_df['Participant_ID'] = dataset_df['Participant_ID']\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "for i_bootstrap in tqdm(range(N_BOOTSTRAP)):\n",
        "    bootstrap_model_dir = model_dir / '{:03d}'.format(i_bootstrap)\n",
        "\n",
        "    # ----------------------------------------------------------------------------\n",
        "    encoder = keras.models.load_model(bootstrap_model_dir / 'encoder.h5', compile=False)\n",
        "    decoder = keras.models.load_model(bootstrap_model_dir / 'decoder.h5', compile=False)\n",
        "\n",
        "    scaler = joblib.load(bootstrap_model_dir / 'scaler.joblib')\n",
        "\n",
        "    enc_age = joblib.load(bootstrap_model_dir / 'age_encoder.joblib')\n",
        "    enc_gender = joblib.load(bootstrap_model_dir / 'gender_encoder.joblib')\n",
        "\n",
        "    # ----------------------------------------------------------------------------\n",
        "    x_normalized = scaler.transform(x_dataset)\n",
        "\n",
        "    # ----------------------------------------------------------------------------\n",
        "    age = dataset_df['Age'].values\n",
        "    age = np.clip(age, 47, 73)\n",
        "    age = age[:, np.newaxis].astype('float32')\n",
        "    one_hot_age = enc_age.transform(age)\n",
        "\n",
        "    gender = dataset_df['Gender'].values[:, np.newaxis].astype('float32')\n",
        "    one_hot_gender = enc_gender.transform(gender)\n",
        "\n",
        "    y_data = np.concatenate((one_hot_age, one_hot_gender), axis=1).astype('float32')\n",
        "\n",
        "    # ----------------------------------------------------------------------------\n",
        "    encoded = encoder(x_normalized, training=False)\n",
        "    reconstruction = decoder(tf.concat([encoded, y_data], axis=1), training=False)\n",
        "\n",
        "    # ----------------------------------------------------------------------------\n",
        "    reconstruction_error = np.mean((x_normalized - reconstruction) ** 2, axis=1)\n",
        "\n",
        "    reconstruction_error_df[('Reconstruction error {:03d}'.format(i_bootstrap))] = reconstruction_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ah4VJ3R1wqwD"
      },
      "source": [
        "Finally, we compute the mean reconstruction error and save the file with the reconstruction errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6AEzjpJ3xvia",
        "colab": {}
      },
      "source": [
        "reconstruction_error_df[reconstruction_error_df.columns[1:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n5rJsceowHC_",
        "colab": {}
      },
      "source": [
        "reconstruction_error_df['Mean reconstruction error'] = reconstruction_error_df[reconstruction_error_df.columns[1:]].mean(axis=1)\n",
        "reconstruction_error_df.to_csv('reconstruction_error.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3xXjXZlo2DB9"
      },
      "source": [
        "## Download predictions\n",
        "Finally, you can download the result in the \"Files\" tab or executing the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T-385ko1v0F4",
        "colab": {}
      },
      "source": [
        "files.download('reconstruction_error.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}